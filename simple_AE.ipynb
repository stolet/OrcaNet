{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_AE.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY2LJZod4_Iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "\n",
        "device = \"cuda\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjynwwmih88J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUikb8B05YCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = 'content/drive/My Drive'\n",
        "load_path = 'sample_data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db4SmXyR54El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/drive/My Drive/data.zip' /content\n",
        "!unzip data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2kUV3-9lxQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dict_to_device(dictionary, device):\n",
        "    for k,v in dictionary.items():\n",
        "        dictionary[k] = v.to(device)\n",
        "    return dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtqziTaxJQZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Killer_Whale_Dataset(Dataset):\n",
        "    # this is a class for the Killer whale dataset\n",
        "    \n",
        "    #first of all override the __init__() method.\n",
        "    def __init__(self, data_folder,transform = None):\n",
        "    \t# super() method is to use the method in its parent class\n",
        "        super().__init__()\n",
        "        self.folder_list = os.listdir(data_folder)\n",
        "        self.img_path = os.path.join(data_folder,'img/')\n",
        "        self.mask_path = os.path.join(data_folder,'mask/')\n",
        "        self.img_list = sorted(os.listdir(self.img_path))\n",
        "        self.mask_list = sorted(os.listdir(self.mask_path))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        self.img = Image.open(self.img_path+self.img_list[idx]).convert('RGB')\n",
        "        self.mask = Image.open(self.mask_path+self.mask_list[idx]).convert('RGB')\n",
        "        if self.transform:\n",
        "            self.img = self.transform(self.img)\n",
        "            self.img = nn.AdaptiveAvgPool2d((224,224))(self.img)\n",
        "            self.mask = self.transform(self.mask)\n",
        "            self.mask = nn.AdaptiveAvgPool2d((224,224))(self.mask)\n",
        "        \n",
        "\n",
        "        sample = {'img':self.img,'mask':self.mask}\n",
        "\n",
        "        \n",
        "            \n",
        "        \n",
        "        return sample\n",
        "    def __len__(self):\n",
        "    \treturn len(self.img_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WqHnDiRJsaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Tensor2Image(t):\n",
        "    trans = transforms.ToPILImage()\n",
        "    img = trans(t[0,:,:,:])\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "class AE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AE, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.conv2a = nn.Conv2d(in_channels=3, out_channels=128,kernel_size=3,stride = 2)\n",
        "        self.conv2b = nn.Conv2d(in_channels=128, out_channels=128,kernel_size=3,stride = 2)\n",
        "        self.conv2c = nn.Conv2d(in_channels=128, out_channels=128,kernel_size=3,stride = 2)\n",
        "        self.conv2d = nn.Conv2d(in_channels=128, out_channels=128,kernel_size=3,stride = 2)\n",
        "        self.conv2e = nn.Conv2d(in_channels=128, out_channels=128,kernel_size=3,stride = 2)\n",
        "        self.conv2f = nn.Conv2d(in_channels=128, out_channels=128,kernel_size=3,stride = 2)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1a = nn.Linear(128,80)\n",
        "        self.fc1b = nn.Linear(80,40)\n",
        "\n",
        "        self.fc2a = nn.Linear(40,80)\n",
        "        self.fc2b = nn.Linear(80,128)\n",
        "\n",
        "        self.convtrans2a = nn.ConvTranspose2d(in_channels=128, out_channels=128,kernel_size=2,stride = 2)\n",
        "        self.convtrans2b = nn.ConvTranspose2d(in_channels=128, out_channels=128,kernel_size=4,stride = 2)\n",
        "        self.convtrans2c = nn.ConvTranspose2d(in_channels=128, out_channels=128,kernel_size=3,stride = 2)\n",
        "        self.convtrans2d = nn.ConvTranspose2d(in_channels=128, out_channels=128,kernel_size=3,stride = 2)\n",
        "        self.convtrans2e = nn.ConvTranspose2d(in_channels=128, out_channels=128,kernel_size=3,stride = 2)\n",
        "        self.convtrans2f = nn.ConvTranspose2d(in_channels=128, out_channels=128,kernel_size=3,stride = 2)\n",
        "        self.convtrans2g = nn.ConvTranspose2d(in_channels=128, out_channels=3,kernel_size=4,stride = 2)\n",
        "        \n",
        "        ## Here, we should define some smart layers\n",
        "    def encode(self, dictionary):\n",
        "        ## Use Deep NN to encode the image\n",
        "\n",
        "        x = dictionary['img']\n",
        "        batch_size = x.shape[0]\n",
        "        \n",
        "        e1 = nn.ReLU()(self.conv2a(x))\n",
        "        e2 = nn.ReLU()(self.conv2b(e1))\n",
        "        e3 = nn.ReLU()(self.conv2c(e2))\n",
        "        e4 = nn.ReLU()(self.conv2d(e3))\n",
        "        e5 = nn.ReLU()(self.conv2e(e4))\n",
        "        e6 = nn.ReLU()(self.conv2f(e5))\n",
        "        j1 = self.pool(e6)\n",
        "        j1 = j1.view(batch_size,-1)\n",
        "        j2 = nn.ReLU()(self.fc1a(j1))\n",
        "        latent_info = self.fc1b(j2)\n",
        "        return latent_info\n",
        "    \n",
        "    def decode(self, latent_info):\n",
        "\n",
        "\n",
        "        ## use the NN to decode to mask\n",
        "        batch_size = latent_info.shape[0]\n",
        "        \n",
        "        h1 = nn.ReLU()(self.fc2a(latent_info))\n",
        "        h2 = self.fc2b(h1) \n",
        "        y = h2.view(batch_size,-1,1,1)\n",
        "\n",
        "        d1 = nn.ReLU()(self.convtrans2a(y))\n",
        "        \n",
        "        d2 = nn.ReLU()(self.convtrans2b(d1))\n",
        "        \n",
        "        d3 = nn.ReLU()(self.convtrans2c(d2))\n",
        "        \n",
        "        d4 = nn.ReLU()(self.convtrans2d(d3))\n",
        "        d5 = nn.ReLU()(self.convtrans2e(d4))\n",
        "        d6 = nn.ReLU()(self.convtrans2f(d5))\n",
        "        d7 = self.convtrans2g(d6)\n",
        "        \n",
        "        \n",
        "        \n",
        "        return {'img': d7}\n",
        "\n",
        "    def forward(self, dictionary):\n",
        "        latent_info = self.encode(dictionary)        \n",
        "        poly_dict = self.decode(latent_info)\n",
        "        return poly_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx_ukno5iV5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])   \n",
        "\n",
        "whale_path = './data'\n",
        "\n",
        "\n",
        "whale_data = Killer_Whale_Dataset(whale_path,transform = transform)\n",
        "print(whale_data[0]['img'].size())\n",
        "ind_val = list(range(0,1))\n",
        "ind_train = list(range(1,len(whale_data)))\n",
        "print(len(whale_data))\n",
        "\n",
        "val_set = torch.utils.data.Subset(whale_data,ind_val)\n",
        "train_set = torch.utils.data.Subset(whale_data,ind_train)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size = 5,shuffle = True,drop_last = False)\n",
        "val_loader = torch.utils.data.DataLoader(val_set,batch_size = 1,shuffle = True,drop_last = False)\n",
        "print(len(val_set))\n",
        "print(len(train_loader))\n",
        "\n",
        "net_test = AE().cuda()\n",
        "\n",
        "## Need to figure out what loss and optimizer to use\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = optim.Adam(net_test.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7PQdOkki6VJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython import display\n",
        "losses = []\n",
        "\n",
        "fig=plt.figure(figsize=(15, 5), dpi= 60, facecolor='w', edgecolor='k')\n",
        "axes=fig.subplots(1,3)\n",
        "\n",
        "for epoch in range(500):\n",
        "    iterator = iter(train_loader)\n",
        "   \n",
        "    for i in range(len(train_loader)):\n",
        "        batch = next(iterator)\n",
        "        dict_to_device(batch, device)\n",
        "        preds = net_test(batch)\n",
        "        loss = loss_fn(preds['img'], batch['mask'])\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "    for ax in axes:\n",
        "        ax.cla() \n",
        "        print(preds['img'].size())\n",
        "        axes[0].imshow(Tensor2Image(preds['img'].cpu()))\n",
        "        axes[0].set_title('good to see?')\n",
        "        axes[1].imshow(Tensor2Image(batch['mask'].cpu()))\n",
        "        axes[1].set_title('ground truth')\n",
        "        axes[2].plot(losses)\n",
        "        axes[2].set_yscale('log')\n",
        "        axes[2].set_xlabel(\"distance\")\n",
        "        axes[2].set_title('Training loss') \n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())\n",
        "        print(\"Plot after epoch {} (iteration {})\".format(epoch, len(losses))) \n",
        "\n",
        "display.display(plt.gcf())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yCnHgqMj4Bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses1 = []\n",
        "fig1=plt.figure(figsize=(15, 5), dpi= 60, facecolor='w', edgecolor='k')\n",
        "axes1=fig1.subplots(1,3)\n",
        "iterator1 = iter(val_loader)\n",
        "for j in range(len(val_loader)):\n",
        "        batch1 = next(iterator1)\n",
        "        dict_to_device(batch1, device)\n",
        "        preds1 = net_test(batch1)\n",
        "        loss = loss_fn(preds1['img'], batch1['mask'])\n",
        "        print(loss)\n",
        "        losses1.append(loss.item())\n",
        "\n",
        "\n",
        "        for ax in axes1:\n",
        "                ax.cla()\n",
        "                axes1[0].imshow(Tensor2Image(preds1['img'].cpu()))\n",
        "                axes1[1].imshow(Tensor2Image(batch1['img'].cpu()))\n",
        "                axes1[2].imshow(Tensor2Image(batch1['mask'].cpu()))\n",
        "display.display(plt.gcf())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7jOFuZlQMqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm3n2K_zQRCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}